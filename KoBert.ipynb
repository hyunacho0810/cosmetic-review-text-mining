{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMR4PO0DQI0pldzpN07BQ9l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6064df33d28049769a17b7c2261df7fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac0e5255f6734a079940789eabb8928f","IPY_MODEL_7c7e424ed7a943148f32c15fb5d5cb1d","IPY_MODEL_a3eb66218e01427992875fe96151aaac"],"layout":"IPY_MODEL_bc4227eb03604d049cc7c2ac6fd9cb09"}},"ac0e5255f6734a079940789eabb8928f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e7062ee754543a2808a702a886489ff","placeholder":"​","style":"IPY_MODEL_a633d6c0ee3e43c9b0965127aeb4a244","value":"tokenizer_config.json: 100%"}},"7c7e424ed7a943148f32c15fb5d5cb1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bd3a093caac4769bbfe93823abdb25b","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad003e7aca8f43faa445adffd545bf38","value":51}},"a3eb66218e01427992875fe96151aaac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff068a51bee244e9b5f1bdfca7d1fc72","placeholder":"​","style":"IPY_MODEL_b739f3cdd9444364b1584af1ceb9032b","value":" 51.0/51.0 [00:00&lt;00:00, 1.84kB/s]"}},"bc4227eb03604d049cc7c2ac6fd9cb09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e7062ee754543a2808a702a886489ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a633d6c0ee3e43c9b0965127aeb4a244":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bd3a093caac4769bbfe93823abdb25b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad003e7aca8f43faa445adffd545bf38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff068a51bee244e9b5f1bdfca7d1fc72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b739f3cdd9444364b1584af1ceb9032b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"381932e9f816444dae921c6fb5460546":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b65923e058704df78c852a2380c704f5","IPY_MODEL_b03ac87da40d4939a23dbfabf88b0bd1","IPY_MODEL_69be624747894a859760f26d0feb9122"],"layout":"IPY_MODEL_834a937f75134d45b08b01410bbee42e"}},"b65923e058704df78c852a2380c704f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_899b38e7a5e34e8f8aabbeffcc381954","placeholder":"​","style":"IPY_MODEL_7bd05bcb1cd84ef28fe7bb6dd69e8660","value":"vocab.txt: 100%"}},"b03ac87da40d4939a23dbfabf88b0bd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae692d66827144ea99daec833d7f08a2","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8fa0d940157b4e4a8e20d7befdbcaf81","value":77779}},"69be624747894a859760f26d0feb9122":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc1afb15b85647fdaf32597cd72c2eba","placeholder":"​","style":"IPY_MODEL_0e8e8d18cd9c4f4fad8b82c25e78a812","value":" 77.8k/77.8k [00:00&lt;00:00, 390kB/s]"}},"834a937f75134d45b08b01410bbee42e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"899b38e7a5e34e8f8aabbeffcc381954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bd05bcb1cd84ef28fe7bb6dd69e8660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae692d66827144ea99daec833d7f08a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fa0d940157b4e4a8e20d7befdbcaf81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc1afb15b85647fdaf32597cd72c2eba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e8e8d18cd9c4f4fad8b82c25e78a812":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de8b0ae9f1e5489c8e225a00bac27030":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31a8136ff3c242959caf1a98b75ce7be","IPY_MODEL_3714923f4c2646f6b42df3fda20055f3","IPY_MODEL_41395f98a6aa429188a78d50985b6ce6"],"layout":"IPY_MODEL_6e91f09041e04bdea20d8d4f6c4b0621"}},"31a8136ff3c242959caf1a98b75ce7be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e39be9967aec4cdab83aa2ee8d419c82","placeholder":"​","style":"IPY_MODEL_dc9f954161b246208281c31cc0f0d052","value":"config.json: 100%"}},"3714923f4c2646f6b42df3fda20055f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84c153eb9a484933ab148e2c6510e8be","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05a23003fd4b4fa0a2b448a9125e23b4","value":426}},"41395f98a6aa429188a78d50985b6ce6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42f10f5d53984d4e8150198a318fdbac","placeholder":"​","style":"IPY_MODEL_1f1b95675b6d40d1815a3e347cd89583","value":" 426/426 [00:00&lt;00:00, 4.96kB/s]"}},"6e91f09041e04bdea20d8d4f6c4b0621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e39be9967aec4cdab83aa2ee8d419c82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc9f954161b246208281c31cc0f0d052":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84c153eb9a484933ab148e2c6510e8be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05a23003fd4b4fa0a2b448a9125e23b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42f10f5d53984d4e8150198a318fdbac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f1b95675b6d40d1815a3e347cd89583":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c0336a4c0f841b79fb73d21fc187e2f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fff90c845c334737b140e23778bd4a56","IPY_MODEL_6aad8d5e198248be8e228f17e27a0b16","IPY_MODEL_bb0c5e8716e74f29934d30051688adeb"],"layout":"IPY_MODEL_d04e070e41c74761ae6925945ff52b3e"}},"fff90c845c334737b140e23778bd4a56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ae49a2e4cf442bcaa2389e59c51f53e","placeholder":"​","style":"IPY_MODEL_cb46d3a4d5d54ee484a03c5bc97063e9","value":"tokenizer_config.json: 100%"}},"6aad8d5e198248be8e228f17e27a0b16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad6648465f3431b82be049374386929","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5a8e4e9ed0a47b4aa6a31d5dd73118f","value":51}},"bb0c5e8716e74f29934d30051688adeb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9acbb783d79d4f06bcc05719bf0b26b4","placeholder":"​","style":"IPY_MODEL_0b31da419a4b44568552e96f12fda4c1","value":" 51.0/51.0 [00:00&lt;00:00, 811B/s]"}},"d04e070e41c74761ae6925945ff52b3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ae49a2e4cf442bcaa2389e59c51f53e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb46d3a4d5d54ee484a03c5bc97063e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dad6648465f3431b82be049374386929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5a8e4e9ed0a47b4aa6a31d5dd73118f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9acbb783d79d4f06bcc05719bf0b26b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b31da419a4b44568552e96f12fda4c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86a1b53812fb4e1f93bc337bd8967537":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b92b970afc3b45f4a8b648895a13771d","IPY_MODEL_1183629240f24f519fb69d8db8dc322d","IPY_MODEL_cd8d06866d354449b28c7cafb6b5ed0e"],"layout":"IPY_MODEL_19de4d8c0500405c9d5bc2aaea10b027"}},"b92b970afc3b45f4a8b648895a13771d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2581565f1e04b8b9a071e61801a0516","placeholder":"​","style":"IPY_MODEL_e63a022d48d64542840acdea141395f2","value":"vocab.txt: 100%"}},"1183629240f24f519fb69d8db8dc322d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8390a52ed2f94b3584e2c8fc4ab13631","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36df00746bc64a518eb4c6306eb71c0c","value":77779}},"cd8d06866d354449b28c7cafb6b5ed0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f498fb7f04e7423894ed330b2cd27ffa","placeholder":"​","style":"IPY_MODEL_c7639153ac3141b2ad23c1f0ccdd05a8","value":" 77.8k/77.8k [00:00&lt;00:00, 1.23MB/s]"}},"19de4d8c0500405c9d5bc2aaea10b027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2581565f1e04b8b9a071e61801a0516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e63a022d48d64542840acdea141395f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8390a52ed2f94b3584e2c8fc4ab13631":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36df00746bc64a518eb4c6306eb71c0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f498fb7f04e7423894ed330b2cd27ffa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7639153ac3141b2ad23c1f0ccdd05a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be71b5f082634b39bea3b1d4cb9925eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_585a3a4466ea415c95f10a904fb9fd41","IPY_MODEL_16d5d5356da0408089382098077f5151","IPY_MODEL_028d19ef5e284cd1bcb31ca37303613c"],"layout":"IPY_MODEL_f5f658250cae4148a3ca93e8ef9fb6cd"}},"585a3a4466ea415c95f10a904fb9fd41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09d9bd7f964a4047908102ac5d720045","placeholder":"​","style":"IPY_MODEL_1bce90827e39497c8117124e66e024c9","value":"config.json: 100%"}},"16d5d5356da0408089382098077f5151":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_660ec8fc0afd45b5ab16d06b0309cd3f","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31af23036ed64302a62d02c0d213ac64","value":426}},"028d19ef5e284cd1bcb31ca37303613c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a8e64018700455eaa650d1703c7f99c","placeholder":"​","style":"IPY_MODEL_983558f98fc94028a17e897171ba4f61","value":" 426/426 [00:00&lt;00:00, 5.48kB/s]"}},"f5f658250cae4148a3ca93e8ef9fb6cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09d9bd7f964a4047908102ac5d720045":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bce90827e39497c8117124e66e024c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"660ec8fc0afd45b5ab16d06b0309cd3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31af23036ed64302a62d02c0d213ac64":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a8e64018700455eaa650d1703c7f99c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"983558f98fc94028a17e897171ba4f61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"367cd616949c4acb9a7f98086c0b10b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a89ceac9420b4687a41da7e76afafa55","IPY_MODEL_a30d8348076949059c691c8d0d6d2eee","IPY_MODEL_14af757fdb674d47aad187ea5169bebc"],"layout":"IPY_MODEL_fdf10d4a156f4e7a9f58a82247e161f3"}},"a89ceac9420b4687a41da7e76afafa55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa8d05bb3da0440dbc41aa6cdcdf3462","placeholder":"​","style":"IPY_MODEL_21b2b2b2f3984825967464eb92f08cbc","value":"tokenizer_config.json: 100%"}},"a30d8348076949059c691c8d0d6d2eee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecd77f1275794381be2d2ca73b88ede1","max":432,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1418847c92d54921b87e5854ed98c91e","value":432}},"14af757fdb674d47aad187ea5169bebc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43e170266b964362b5ee2e0539fa1ad1","placeholder":"​","style":"IPY_MODEL_dfd20e6351a14f8da3b297872ed3a3ae","value":" 432/432 [00:00&lt;00:00, 15.9kB/s]"}},"fdf10d4a156f4e7a9f58a82247e161f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa8d05bb3da0440dbc41aa6cdcdf3462":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21b2b2b2f3984825967464eb92f08cbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecd77f1275794381be2d2ca73b88ede1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1418847c92d54921b87e5854ed98c91e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43e170266b964362b5ee2e0539fa1ad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfd20e6351a14f8da3b297872ed3a3ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04ef0609c6984cc894308f9bd68e7c4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c72fc6d4458481bab8e42ec0f4de9ca","IPY_MODEL_779cdde15ac1439db016359f243ba3a3","IPY_MODEL_ca29bcb35455400c81e95fd9a08d2ebc"],"layout":"IPY_MODEL_43f4bd6d66c4428ebbeb7e784eeae365"}},"3c72fc6d4458481bab8e42ec0f4de9ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c6c981df8f44d62b09d2e5314951c56","placeholder":"​","style":"IPY_MODEL_b3b2272a8b314ba58b5cedd0fe719bdd","value":"special_tokens_map.json: 100%"}},"779cdde15ac1439db016359f243ba3a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c64429c7696e4a6987d185a058be559a","max":244,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0500915be636415c8e0df07715bc1277","value":244}},"ca29bcb35455400c81e95fd9a08d2ebc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee6e06c08a984a7ab607a4cab662c15e","placeholder":"​","style":"IPY_MODEL_3f9e008e11454b69b3ca1e61f4d2877c","value":" 244/244 [00:00&lt;00:00, 7.35kB/s]"}},"43f4bd6d66c4428ebbeb7e784eeae365":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c6c981df8f44d62b09d2e5314951c56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3b2272a8b314ba58b5cedd0fe719bdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c64429c7696e4a6987d185a058be559a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0500915be636415c8e0df07715bc1277":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee6e06c08a984a7ab607a4cab662c15e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f9e008e11454b69b3ca1e61f4d2877c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254,"referenced_widgets":["6064df33d28049769a17b7c2261df7fa","ac0e5255f6734a079940789eabb8928f","7c7e424ed7a943148f32c15fb5d5cb1d","a3eb66218e01427992875fe96151aaac","bc4227eb03604d049cc7c2ac6fd9cb09","0e7062ee754543a2808a702a886489ff","a633d6c0ee3e43c9b0965127aeb4a244","3bd3a093caac4769bbfe93823abdb25b","ad003e7aca8f43faa445adffd545bf38","ff068a51bee244e9b5f1bdfca7d1fc72","b739f3cdd9444364b1584af1ceb9032b","381932e9f816444dae921c6fb5460546","b65923e058704df78c852a2380c704f5","b03ac87da40d4939a23dbfabf88b0bd1","69be624747894a859760f26d0feb9122","834a937f75134d45b08b01410bbee42e","899b38e7a5e34e8f8aabbeffcc381954","7bd05bcb1cd84ef28fe7bb6dd69e8660","ae692d66827144ea99daec833d7f08a2","8fa0d940157b4e4a8e20d7befdbcaf81","fc1afb15b85647fdaf32597cd72c2eba","0e8e8d18cd9c4f4fad8b82c25e78a812","de8b0ae9f1e5489c8e225a00bac27030","31a8136ff3c242959caf1a98b75ce7be","3714923f4c2646f6b42df3fda20055f3","41395f98a6aa429188a78d50985b6ce6","6e91f09041e04bdea20d8d4f6c4b0621","e39be9967aec4cdab83aa2ee8d419c82","dc9f954161b246208281c31cc0f0d052","84c153eb9a484933ab148e2c6510e8be","05a23003fd4b4fa0a2b448a9125e23b4","42f10f5d53984d4e8150198a318fdbac","1f1b95675b6d40d1815a3e347cd89583"]},"id":"0Vx_UYhJcVjB","executionInfo":{"status":"ok","timestamp":1711887478751,"user_tz":-540,"elapsed":17466,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"872e5ade-5273-4c67-a0e8-be2fd36aaada"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6064df33d28049769a17b7c2261df7fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"381932e9f816444dae921c6fb5460546"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de8b0ae9f1e5489c8e225a00bac27030"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[ 2,  0,  0,  0,  0, 54,  3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n"]}],"source":["from transformers import BertTokenizer\n","\n","# 토크나이저 불러오기\n","tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n","\n","# 입력 문장\n","text = \"한국어 문장을 처리하는 예시입니다.\"\n","\n","# 문장 토큰화 및 인코딩\n","encoded_input = tokenizer(text, padding=True, truncation=True, max_length=64, return_tensors='pt')\n","\n","# 전처리된 데이터 확인\n","print(encoded_input)"]},{"cell_type":"code","source":["import pandas as pd\n","\n","# 엑셀 파일 로드\n","excel_file = '/content/토리든 스킨 3.30 데이터.xlsx'\n","df = pd.read_excel(excel_file)\n","\n","# 데이터 확인\n","print(df.head())\n","\n","# 데이터 전처리 수행\n","# 여기에 데이터 전처리 코드를 추가하세요\n","\n","# 열 이름들을 리스트로 분리\n","column_names = ['제목', '제목_링크', '썸네일', 'txt_inner', 'txt', 'btn_recom', 'date', 'txt1', 'txt2', 'tag', 'tag1', 'tag2', 'tag3']\n","\n","# 각 열의 데이터를 가져와서 처리\n","for column_name in column_names:\n","    column_data = df[column_name]\n","    # 여기에 각 열의 데이터를 처리하는 코드를 추가하세요\n","\n","# 전처리된 데이터 출력\n","print(column_data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33oQ22HPcphz","executionInfo":{"status":"ok","timestamp":1711887878454,"user_tz":-540,"elapsed":491,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"f44b9d7e-bb0d-4571-bebb-2874b72c1457"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3  \n","0  NaN  NaN  \n","1   각질   주름  \n","2  NaN  NaN  \n","3  NaN  NaN  \n","4  NaN  NaN  \n","0    NaN\n","1     주름\n","2    NaN\n","3    NaN\n","4    NaN\n","Name: tag3, dtype: object\n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","from transformers import BertTokenizer\n","\n","# 엑셀 파일 로드\n","excel_file = '/content/토리든 스킨 3.30 데이터.xlsx'\n","df = pd.read_excel(excel_file)\n","\n","# 데이터 확인\n","print(df.head())\n","\n","# KoBERT 토크나이저 불러오기\n","tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n","\n","# 텍스트 열 선택\n","text_column = df['txt_inner']\n","\n","# 텍스트 데이터 전처리 및 토큰화\n","tokenized_texts = []\n","for text in text_column:\n","    # 전처리 작업 (예: 문장 부호 제거 등)\n","    processed_text = text.replace(\",\", \"\")\n","    processed_text = text.replace(\".\", \"\")  # 예시로 문장 부호를 제거하는 작업을 수행했습니다. 실제 전처리 과정은 데이터의 특성에 따라 달라집니다.\n","    processed_text = re.sub('[ㅋㅎ!~]', '', text)\n","    # 토큰화\n","    tokenized_text = tokenizer.tokenize(processed_text)\n","\n","    # 전처리된 토큰화된 텍스트를 리스트에 추가\n","    tokenized_texts.append(tokenized_text)\n","\n","# 전처리된 데이터를 새로운 열로 추가\n","df['processed_text'] = tokenized_texts\n","\n","# 전처리된 데이터를 새로운 엑셀 파일로 저장\n","output_excel_file = 'preprocessed_data.xlsx'\n","df.to_excel(output_excel_file, index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ky_3XG-We0M2","executionInfo":{"status":"ok","timestamp":1711888430842,"user_tz":-540,"elapsed":625,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"8a5f9af8-1946-466b-e257-b3beb039cb61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3  \n","0  NaN  NaN  \n","1   각질   주름  \n","2  NaN  NaN  \n","3  NaN  NaN  \n","4  NaN  NaN  \n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","from transformers import BertTokenizer, BertModel\n","\n","# 새로운 단어 추가할 리스트\n","new_words = ['ㅋ', 'ㅎ', '!', '~']\n","\n","# 새로운 단어 어휘집에 추가\n","tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n","tokenizer.add_tokens(new_words)\n","\n","# 엑셀 파일 로드\n","excel_file = '/content/토리든 스킨 3.30 데이터.xlsx'\n","df = pd.read_excel(excel_file)\n","\n","# 데이터 확인\n","print(df.head())\n","\n","# 텍스트 열 선택\n","text_column = df['txt']\n","\n","# 텍스트 데이터 전처리 및 토큰화\n","tokenized_texts = []\n","for text in text_column:\n","    # 정규 표현식을 사용하여 특수문자 제거\n","    processed_text = re.sub(r'[^\\w\\s]', '', text)\n","\n","    # 토큰화\n","    tokenized_text = tokenizer.tokenize(processed_text)\n","\n","    # 전처리된 토큰화된 텍스트를 리스트에 추가\n","    tokenized_texts.append(tokenized_text)\n","\n","# 전처리된 데이터 출력\n","print(tokenized_texts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4aFLGUDRgxzU","executionInfo":{"status":"ok","timestamp":1711888648181,"user_tz":-540,"elapsed":1248,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"8282bed4-a120-4158-a854-59d912193261"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3  \n","0  NaN  NaN  \n","1   각질   주름  \n","2  NaN  NaN  \n","3  NaN  NaN  \n","4  NaN  NaN  \n","[['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]'], ['[UNK]', '[UNK]']]\n"]}]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","from transformers import BertTokenizer\n","\n","# 엑셀 파일 로드\n","excel_file = '/content/토리든 스킨 3.30 데이터.xlsx'\n","df = pd.read_excel(excel_file)\n","\n","# 데이터 확인\n","print(df.head())\n","\n","# KoBERT 토크나이저 불러오기\n","tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n","\n","# 텍스트 열 선택\n","text_column = df['txt_inner']\n","\n","# 텍스트 데이터 전처리 및 토큰화\n","tokenized_texts = []\n","for text in text_column:\n","    # 전처리 작업 (예: 문장 부호 제거 등)\n","    processed_text = text.replace(\",\", \"\")\n","    processed_text = text.replace(\".\", \"\")  # 예시로 문장 부호를 제거하는 작업을 수행했습니다. 실제 전처리 과정은 데이터의 특성에 따라 달라집니다.\n","    processed_text = re.sub('[ㅋㅎ!~]', '', text)\n","    # 토큰화\n","    tokenized_text = tokenizer.tokenize(processed_text)\n","\n","    # 전처리된 토큰화된 텍스트를 리스트에 추가\n","    tokenized_texts.append(tokenized_text)\n","\n","# 전처리된 데이터를 새로운 열로 추가\n","df['processed_text'] = tokenized_texts\n","\n","# 전처리된 데이터를 새로운 엑셀 파일로 저장\n","output_excel_file = 'preprocessed_data2.xlsx'\n","df.to_excel(output_excel_file, index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0eiQVG4hFuz","executionInfo":{"status":"ok","timestamp":1711888780137,"user_tz":-540,"elapsed":4,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"6f629fbb-2c15-4c5d-d948-68bdef2baa4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3  \n","0  NaN  NaN  \n","1   각질   주름  \n","2  NaN  NaN  \n","3  NaN  NaN  \n","4  NaN  NaN  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertTokenizer\n","\n","# 엑셀 파일 로드\n","excel_file = '/content/토리든 스킨 3.30 데이터.xlsx'\n","df = pd.read_excel(excel_file)\n","\n","# 데이터 확인\n","print(df.head())\n","\n","# KoBERT 토크나이저 불러오기\n","tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n","\n","# 텍스트 열 선택\n","text_column = df['txt']\n","\n","# 텍스트 데이터 전처리 및 토큰화\n","tokenized_texts = []\n","for text in text_column:\n","    # 한글 문장 부호를 공백으로 대체\n","    processed_text = text.replace('ㅋ', ' ').replace('ㅎ', ' ').replace('!', ' ').replace('~', ' ')\n","\n","    # 토큰화\n","    tokenized_text = tokenizer.tokenize(processed_text)\n","\n","    # 전처리된 토큰화된 텍스트를 리스트에 추가\n","    tokenized_texts.append(tokenized_text)\n","\n","# 전처리된 데이터를 새로운 열로 추가\n","df['processed_text'] = tokenized_texts\n","\n","# 전처리된 데이터를 새로운 엑셀 파일로 저장\n","output_excel_file = 'preprocessed_data4.xlsx'\n","df.to_excel(output_excel_file, index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWnxZhxiiQqU","executionInfo":{"status":"ok","timestamp":1711889168634,"user_tz":-540,"elapsed":1200,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"448873bb-b3cd-461b-9a04-71295478bf05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3  \n","0  NaN  NaN  \n","1   각질   주름  \n","2  NaN  NaN  \n","3  NaN  NaN  \n","4  NaN  NaN  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# 엑셀 파일 로드\n","excel_file = '/content/토리든 스킨 3.30 데이터.xlsx'\n","df = pd.read_excel(excel_file)\n","\n","# 데이터 확인\n","print(df.head())\n","\n","# 데이터 전처리 수행\n","# 여기에 데이터 전처리 코드를 추가하세요\n","\n","# 열 이름들을 리스트로 분리\n","column_names = ['제목', '제목_링크', '썸네일', 'txt_inner', 'txt', 'btn_recom', 'date', 'txt1', 'txt2', 'tag', 'tag1', 'tag2', 'tag3']\n","\n","# 각 열의 데이터를 가져와서 처리\n","for column_name in column_names:\n","    column_data = df[column_name]\n","    # 여기에 각 열의 데이터를 처리하는 코드를 추가하세요\n","# KoBERT 토크나이저 불러오기\n","tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n","\n","# 텍스트 열 선택\n","text_column = df['txt']\n","\n","# 텍스트 데이터 전처리 및 토큰화\n","tokenized_texts = []\n","for text in text_column:\n","    # 문장 부호를 기준으로 텍스트를 토큰화\n","    tokenized_text = tokenizer.tokenize(text)\n","\n","    # 전처리된 토큰화된 텍스트를 리스트에 추가\n","    tokenized_texts.append(tokenized_text)\n","\n","# 전처리된 텍스트를 데이터프레임에 추가\n","df['preprocessed_txt'] = tokenized_texts\n","\n","# 수정된 데이터프레임 확인\n","print(df.head())\n","\n","# 수정된 데이터프레임을 엑셀 파일로 저장\n","output_excel_file = 'preprocessed_data5.xlsx'\n","df.to_excel(output_excel_file, index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkxqnC1Nj-f-","executionInfo":{"status":"ok","timestamp":1711889485705,"user_tz":-540,"elapsed":1074,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"a47668c5-e9ed-4d66-d99e-655610613547"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3  \n","0  NaN  NaN  \n","1   각질   주름  \n","2  NaN  NaN  \n","3  NaN  NaN  \n","4  NaN  NaN  \n","            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3 preprocessed_txt  \n","0  NaN  NaN   [[UNK], [UNK]]  \n","1   각질   주름   [[UNK], [UNK]]  \n","2  NaN  NaN   [[UNK], [UNK]]  \n","3  NaN  NaN   [[UNK], [UNK]]  \n","4  NaN  NaN   [[UNK], [UNK]]  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertTokenizer\n","\n","# 엑셀 파일 로드\n","excel_file = '/content/토리든 스킨 3.30 데이터.xlsx'\n","df = pd.read_excel(excel_file)\n","\n","# 데이터 확인\n","print(df.head())\n","\n","# KoBERT 토크나이저 불러오기\n","tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n","\n","# 추가할 단어\n","new_words = ['[UNK]']\n","\n","# 어휘집에 단어 추가\n","tokenizer.add_tokens(new_words)\n","\n","# 텍스트 열 선택\n","text_column = df['txt']\n","\n","# 텍스트 데이터 전처리 및 토큰화\n","tokenized_texts = []\n","for text in text_column:\n","    # 문장을 단어로 분할\n","    tokenized_text = tokenizer.tokenize(text)\n","\n","    # 전처리된 토큰화된 텍스트를 리스트에 추가\n","    tokenized_texts.append(tokenized_text)\n","\n","# 전처리된 텍스트를 데이터프레임에 추가\n","df['tokenized_txt'] = tokenized_texts\n","\n","# 수정된 데이터프레임 확인\n","print(df.head())\n","\n","# 수정된 데이터프레임을 엑셀 파일로 저장\n","output_excel_file = 'preprocessed_data8.xlsx'\n","df.to_excel(output_excel_file, index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4c0336a4c0f841b79fb73d21fc187e2f","fff90c845c334737b140e23778bd4a56","6aad8d5e198248be8e228f17e27a0b16","bb0c5e8716e74f29934d30051688adeb","d04e070e41c74761ae6925945ff52b3e","0ae49a2e4cf442bcaa2389e59c51f53e","cb46d3a4d5d54ee484a03c5bc97063e9","dad6648465f3431b82be049374386929","e5a8e4e9ed0a47b4aa6a31d5dd73118f","9acbb783d79d4f06bcc05719bf0b26b4","0b31da419a4b44568552e96f12fda4c1","86a1b53812fb4e1f93bc337bd8967537","b92b970afc3b45f4a8b648895a13771d","1183629240f24f519fb69d8db8dc322d","cd8d06866d354449b28c7cafb6b5ed0e","19de4d8c0500405c9d5bc2aaea10b027","e2581565f1e04b8b9a071e61801a0516","e63a022d48d64542840acdea141395f2","8390a52ed2f94b3584e2c8fc4ab13631","36df00746bc64a518eb4c6306eb71c0c","f498fb7f04e7423894ed330b2cd27ffa","c7639153ac3141b2ad23c1f0ccdd05a8","be71b5f082634b39bea3b1d4cb9925eb","585a3a4466ea415c95f10a904fb9fd41","16d5d5356da0408089382098077f5151","028d19ef5e284cd1bcb31ca37303613c","f5f658250cae4148a3ca93e8ef9fb6cd","09d9bd7f964a4047908102ac5d720045","1bce90827e39497c8117124e66e024c9","660ec8fc0afd45b5ab16d06b0309cd3f","31af23036ed64302a62d02c0d213ac64","7a8e64018700455eaa650d1703c7f99c","983558f98fc94028a17e897171ba4f61"]},"id":"z5untg38kkDk","executionInfo":{"status":"ok","timestamp":1711935190963,"user_tz":-540,"elapsed":3657,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"3fe385e4-257d-40ac-8a41-2264b642c314"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3  \n","0  NaN  NaN  \n","1   각질   주름  \n","2  NaN  NaN  \n","3  NaN  NaN  \n","4  NaN  NaN  \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c0336a4c0f841b79fb73d21fc187e2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a1b53812fb4e1f93bc337bd8967537"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be71b5f082634b39bea3b1d4cb9925eb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["            제목         제목_링크  \\\n","0     micc****  javascript:;   \n","1          달봉씨  javascript:;   \n","2       lu****  javascript:;   \n","3       hyeonv  javascript:;   \n","4  tlswlal****  javascript:;   \n","\n","                                                 썸네일  \\\n","0  https://static.oliveyoung.co.kr/pc-static-root...   \n","1  https://image.oliveyoung.co.kr/uploads/images/...   \n","2  https://static.oliveyoung.co.kr/pc-static-root...   \n","3  https://static.oliveyoung.co.kr/pc-static-root...   \n","4  https://static.oliveyoung.co.kr/pc-static-root...   \n","\n","                                           txt_inner       txt  \\\n","0            세일할 때 사봤는데 순하고 얼굴톤이 밝아지네요 ㅋ 데일리용으로 강추~ㅎ  복합성에 좋아요   \n","1  토리든 세럼 크림 사용중인데 토너가 다 떨어져서 토리든걸로 사봤어요~닦아낸 후에도 ...   건성에 좋아요   \n","2        재구매했습니다 ! 수부지인데 잘 맞는 것 같아요 또 구매할 의사 있습니다 ㅎㅎ  복합성에 좋아요   \n","3                자극어뵤이 수분 순하게 충전해줘서 조와요 무겁다는 느낌도안들어용  복합성에 좋아요   \n","4                  안써봨ㅅ는대 토리든이면 뭐든 쟁여탬이죠 ㅎ 다들 토라든하세여   지성에 좋아요   \n","\n","                          btn_recom        date     txt1      txt2  tag tag1  \\\n","0  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","1  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  복합성   웜톤   \n","2  이 리뷰가 도움이 돼요!                  0  2024.03.26  진정에 좋아요     보통이에요  NaN  NaN   \n","3  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","4  이 리뷰가 도움이 돼요!                  0  2024.03.26  보습에 좋아요  자극없이 순해요  NaN  NaN   \n","\n","  tag2 tag3   tokenized_txt  \n","0  NaN  NaN  [[UNK], [UNK]]  \n","1   각질   주름  [[UNK], [UNK]]  \n","2  NaN  NaN  [[UNK], [UNK]]  \n","3  NaN  NaN  [[UNK], [UNK]]  \n","4  NaN  NaN  [[UNK], [UNK]]  \n"]}]},{"cell_type":"code","source":["#필요 패키지 설치\n","!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch\n","!pip install pandas\n","#KoBERT 깃허브에서 불러오기\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd\n","#KoBERT\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","#transformer\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","#GPU 설정\n","device = torch.device(\"cuda:0\")\n","#bertmodel의 vocabulary\n","bertmodel, vocab = get_pytorch_kobert_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DDtC95Dplmm0","executionInfo":{"status":"error","timestamp":1711890044734,"user_tz":-540,"elapsed":171855,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"cad72d6a-b4c3-43b7-e7aa-e42e08efcabd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.25.2)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n","Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2024.2.2)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.20.3\n","    Uninstalling graphviz-0.20.3:\n","      Successfully uninstalled graphviz-0.20.3\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (1.25.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (3.0.9)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (24.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp310-cp310-linux_x86_64.whl size=661764 sha256=43ed3e374f7fbe418d7d7294f1b66730197d119cec4b9f09c24566d740732bac\n","  Stored in directory: /root/.cache/pip/wheels/1a/1e/0d/99f55911d90f2b95b9f7c176d5813ef3622894a4b30fde6bd3\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.0/769.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.2) (1.25.2)\n","Collecting tokenizers==0.8.1.rc1 (from transformers==3.0.2)\n","  Downloading tokenizers-0.8.1rc1.tar.gz (97 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.2) (24.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.2) (3.13.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.2) (2.31.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.2) (4.66.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.2) (2023.12.25)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.2) (0.1.99)\n","Collecting sacremoses (from transformers==3.0.2)\n","  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.0.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.0.2) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.0.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.0.2) (2024.2.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==3.0.2) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==3.0.2) (1.3.2)\n","Building wheels for collected packages: tokenizers\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n","\u001b[0mFailed to build tokenizers\n","\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m906.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-1xtgi8fj\n","  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-1xtgi8fj\n","  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting boto3<=1.15.18 (from kobert==0.2.3)\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from kobert==0.2.3) (0.10.0)\n","Collecting mxnet<=1.7.0.post2,>=1.4.0 (from kobert==0.2.3)\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of kobert to determine which version is compatible with other requirements. This could take a while.\n","\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime<=1.8.0,==1.8.0 (from kobert) (from versions: 1.12.0, 1.12.1, 1.13.1, 1.14.0, 1.14.1, 1.15.0, 1.15.1, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.17.0, 1.17.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime<=1.8.0,==1.8.0\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/mxnet/numpy/utils.py:37: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  bool = onp.bool\n"]},{"output_type":"error","ename":"AttributeError","evalue":"module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-94c0f1bf7600>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgluonnlp\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gluonnlp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mxnet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mxnet/contrib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mxnet/contrib/text/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mxnet/contrib/text/embedding.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_np_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_mx_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy_extension\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_mx_npx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mxnet/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmultiarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_register\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mxnet/numpy/multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_internal\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_npi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_storage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_get_np_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import,unused-wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mxnet/numpy/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mint64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mbool_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'testing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"]}]},{"cell_type":"code","source":["pip show onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5xoiiNLRzVh","executionInfo":{"status":"ok","timestamp":1711935027230,"user_tz":-540,"elapsed":1665,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"cf449b9d-ae92-4fa8-87a3-dd9cd8322e78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Package(s) not found: onnxruntime\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["pip install onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0oAo-WsdSKsy","executionInfo":{"status":"ok","timestamp":1711935121243,"user_tz":-540,"elapsed":12244,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"e6289194-57cd-4bdc-b550-0c14f1e2d093"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnxruntime\n","  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# 엑셀 파일 경로 설정\n","excel_file_path = \"/content/토리든 스킨 3.30 데이터.xlsx\"\n","\n","# 읽어올 열의 이름 설정\n","column_name = \"txt_inner\"\n","\n","# 엑셀 파일에서 데이터 로드\n","data = pd.read_excel(excel_file_path)\n","\n","# 선택한 열의 데이터만 추출\n","selected_column_data = data[column_name]\n","\n","# KoBERT tokenizer를 불러오기\n","tokenizer = BertTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n","\n","def preprocess_text(text):\n","    # 문장부호 삭제\n","    text = text.replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\";\", \"\").replace(\":\", \"\")\n","    # KoBERT 토크나이저를 사용하여 단어 단위로 토큰화\n","    tokens = tokenizer.tokenize(text)\n","    return tokens\n","\n","# 전처리된 데이터를 저장할 리스트 초기화\n","preprocessed_data = []\n","\n","# 각 행의 데이터를 전처리하여 리스트에 저장\n","for index, row in selected_column_data.iteritems():\n","    input_text = str(row)  # 각 셀의 데이터를 문자열로 변환\n","    preprocessed_text = preprocess_text(input_text)\n","    preprocessed_data.append(preprocessed_text)\n","\n","# 전처리된 데이터로 데이터프레임 생성\n","preprocessed_df = pd.DataFrame(preprocessed_data)\n","\n","# 전처리된 데이터를 새로운 엑셀 파일로 저장\n","output_excel_file = \"preprocessed_data9.xlsx\"\n","preprocessed_df.to_excel(output_excel_file, index=False)\n","\n","print(\"전처리된 데이터가 {} 파일로 저장되었습니다.\".format(output_excel_file))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":492,"referenced_widgets":["367cd616949c4acb9a7f98086c0b10b8","a89ceac9420b4687a41da7e76afafa55","a30d8348076949059c691c8d0d6d2eee","14af757fdb674d47aad187ea5169bebc","fdf10d4a156f4e7a9f58a82247e161f3","fa8d05bb3da0440dbc41aa6cdcdf3462","21b2b2b2f3984825967464eb92f08cbc","ecd77f1275794381be2d2ca73b88ede1","1418847c92d54921b87e5854ed98c91e","43e170266b964362b5ee2e0539fa1ad1","dfd20e6351a14f8da3b297872ed3a3ae","04ef0609c6984cc894308f9bd68e7c4f","3c72fc6d4458481bab8e42ec0f4de9ca","779cdde15ac1439db016359f243ba3a3","ca29bcb35455400c81e95fd9a08d2ebc","43f4bd6d66c4428ebbeb7e784eeae365","7c6c981df8f44d62b09d2e5314951c56","b3b2272a8b314ba58b5cedd0fe719bdd","c64429c7696e4a6987d185a058be559a","0500915be636415c8e0df07715bc1277","ee6e06c08a984a7ab607a4cab662c15e","3f9e008e11454b69b3ca1e61f4d2877c"]},"id":"SVvfa7WnSp9I","executionInfo":{"status":"error","timestamp":1711935473545,"user_tz":-540,"elapsed":1347,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"681a8f60-9646-4aa9-b172-f386880f545f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"367cd616949c4acb9a7f98086c0b10b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04ef0609c6984cc894308f9bd68e7c4f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n"]},{"output_type":"error","ename":"TypeError","evalue":"stat: path should be string, bytes, os.PathLike or integer, not NoneType","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-71084cac4f44>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# KoBERT tokenizer를 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skt/kobert-base-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2046\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2049\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2285\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m             raise OSError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     ):\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             raise ValueError(\n\u001b[1;32m    201\u001b[0m                 \u001b[0;34mf\"Can't find a vocabulary file at path '{vocab_file}'. To load the vocabulary from a Google pretrained\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# 엑셀 파일 경로 설정\n","excel_file_path = \"/content/토리든 스킨 3.30 데이터.xlsx\"\n","\n","# 읽어올 열의 이름 설정\n","column_name = \"txt_inner\"\n","\n","# 엑셀 파일에서 데이터 로드\n","data = pd.read_excel(excel_file_path)\n","\n","# 선택한 열의 데이터만 추출\n","selected_column_data = data[column_name]\n","\n","# KoBERT tokenizer를 불러오기\n","tokenizer = BertTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n","\n","def preprocess_text(text):\n","    # 문장부호 삭제\n","    text = text.replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\";\", \"\").replace(\":\", \"\")\n","    # KoBERT 토크나이저를 사용하여 단어 단위로 토큰화\n","    tokens = tokenizer.tokenize(text)\n","    return tokens\n","\n","# 전처리된 데이터를 저장할 리스트 초기화\n","preprocessed_data = []\n","\n","# 각 행의 데이터를 전처리하여 리스트에 저장\n","for index, row in selected_column_data.iteritems():\n","    input_text = str(row)  # 각 셀의 데이터를 문자열로 변환\n","    preprocessed_text = preprocess_text(input_text)\n","    preprocessed_data.append(preprocessed_text)\n","\n","# 전처리된 데이터로 데이터프레임 생성\n","preprocessed_df = pd.DataFrame(preprocessed_data)\n","\n","# 전처리된 데이터를 새로운 엑셀 파일로 저장\n","output_excel_file = \"preprocessed_data.xlsx\"\n","preprocessed_df.to_excel(output_excel_file, index=False)\n","\n","print(\"전처리된 데이터가 {} 파일로 저장되었습니다.\".format(output_excel_file))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"3hBX6t5kTnvU","executionInfo":{"status":"error","timestamp":1711935526476,"user_tz":-540,"elapsed":329,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"33a90545-121f-4415-dff1-b1c12faa0691"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n"]},{"output_type":"error","ename":"TypeError","evalue":"stat: path should be string, bytes, os.PathLike or integer, not NoneType","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-79c401a09aa3>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# KoBERT tokenizer를 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skt/kobert-base-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2046\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2049\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2285\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m             raise OSError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     ):\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             raise ValueError(\n\u001b[1;32m    201\u001b[0m                 \u001b[0;34mf\"Can't find a vocabulary file at path '{vocab_file}'. To load the vocabulary from a Google pretrained\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"]}]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"QyGpvBppT8wt","executionInfo":{"status":"error","timestamp":1711935703291,"user_tz":-540,"elapsed":314,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"c528ef96-55c0-4949-a816-1cf98b49acaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n"]},{"output_type":"error","ename":"TypeError","evalue":"stat: path should be string, bytes, os.PathLike or integer, not NoneType","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-449352ac954f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skt/kobert-base-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2046\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2049\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2285\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m             raise OSError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     ):\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             raise ValueError(\n\u001b[1;32m    201\u001b[0m                 \u001b[0;34mf\"Can't find a vocabulary file at path '{vocab_file}'. To load the vocabulary from a Google pretrained\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"]}]}]}