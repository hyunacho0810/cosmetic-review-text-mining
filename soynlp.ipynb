{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO2jd/K+LJ1TkF6Bj4BI/IL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install soynlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W-UCPiDpyL_f","executionInfo":{"status":"ok","timestamp":1715787323918,"user_tz":-540,"elapsed":20079,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"30ca67d7-acd2-47a5-9af1-1c62284e08ea"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting soynlp\n","  Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.8/416.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.25.2)\n","Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from soynlp) (5.9.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.5.0)\n","Installing collected packages: soynlp\n","Successfully installed soynlp-0.0.493\n"]}]},{"cell_type":"code","source":["!pip install langdetect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtiSELybyXEI","executionInfo":{"status":"ok","timestamp":1715787341335,"user_tz":-540,"elapsed":17426,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"976c9719-3533-4aa2-bf0a-d424077dee39"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=dbe0dfd5996108fcb69ba10efc1f61d93cb602aac537161cbbda84c11915144f\n","  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","from soynlp.normalizer import emoticon_normalize\n","from soynlp.tokenizer import RegexTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from langdetect import detect\n","# 데이터 불러오기\n","data = pd.read_excel(\"/content/토리든 토너 891개.xlsx\")\n","\n","reviews = data['필드3']\n","\n","tokenizer = RegexTokenizer()\n","\n","stopwords_url = \"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\"\n","stopwords = pd.read_csv(stopwords_url, header=None)[0].tolist()\n","\n","def remove_special_characters(text):\n","    text = emoticon_normalize(text)\n","    # 모든 특수문자 및 이모티콘 제거\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    # 특정 기호 수정 (예: ㅋ, ㅎ, ㅜ, ㅠ 등)\n","    text = re.sub(r'(ㅋ|ㅎ|ㅜ|ㅠ)+', '', text)\n","    text = re.sub(r'\\s+', ' ', text)    # 공백 제거\n","    text = re.sub('([ㄱ-ㅎㅏ-ㅣ]+)', '', text)    # 한글 자음, 모음 제거\n","    text = re.sub('[^\\w\\s\\n]', '', text)\n","    return text\n","def remove_non_korean_reviews(texts):\n","    filtered_texts = []\n","    for text in texts:\n","        try:\n","\n","            if detect(text) != 'ko':\n","                continue\n","        except:\n","            # 언어 감지에 실패한 경우도 제외\n","            continue\n","        filtered_texts.append(text)\n","    return filtered_texts\n","\n","# 전처리 함수 정의\n","def preprocess_text(text):\n","    text = remove_special_characters(text)\n","    tokens = tokenizer.tokenize(text)\n","    tokens = [token for token in tokens if token not in stopwords]\n","    return ' '.join(tokens)\n","\n","# 전처리된 리뷰 데이터 생성\n","preprocessed_reviews = [preprocess_text(review) for review in reviews]\n","\n","# 데이터프레임으로 변환\n","preprocessed_data = pd.DataFrame({'preprocessed_review': preprocessed_reviews})\n","\n","# 전처리된 데이터를 엑셀 파일로 저장\n","preprocessed_data_file = \"preprocessed_toner_reviews.xlsx\"\n","preprocessed_data.to_excel(preprocessed_data_file, index=False)"],"metadata":{"id":"7YRVFUQBx2as","executionInfo":{"status":"ok","timestamp":1715787348001,"user_tz":-540,"elapsed":3459,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c9690ca-a922-4b52-aa14-ba78edcfbd04"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/soynlp/tokenizer/_tokenizer.py:19: FutureWarning: Possible nested set at position 13\n","  ('english & latin', re.compile(u\"[a-zA-ZÀ-ÿ]+[[`']?s]*|[a-zA-ZÀ-ÿ]+\", re.UNICODE))\n"]}]}]}