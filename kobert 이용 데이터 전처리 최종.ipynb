{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMUzxT7XU9cBF6yMnNFxhRx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJHIrvOLZkiS","executionInfo":{"status":"ok","timestamp":1715787211854,"user_tz":-540,"elapsed":28520,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"65ddaa99-f018-4c5b-c0fc-55fee8511ff7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-lk5tcc_f/kobert-tokenizer_2b93f295c3ea4923b698b7bfae457f74\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-lk5tcc_f/kobert-tokenizer_2b93f295c3ea4923b698b7bfae457f74\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: kobert_tokenizer\n","  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4633 sha256=c3f967158e5f0f5672b584fdb94f83e2a67f73439c83b15060a876bb5b918fc0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-v3s8sgi4/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n","Successfully built kobert_tokenizer\n","Installing collected packages: kobert_tokenizer\n","Successfully installed kobert_tokenizer-0.1\n"]}]},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dt1-Oqir40hc","executionInfo":{"status":"ok","timestamp":1711945259929,"user_tz":-540,"elapsed":11826,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"91ce9b10-75a5-4d54-e92f-aa2690d92c29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.0)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gxjOIPR_pGQ","executionInfo":{"status":"ok","timestamp":1714712777087,"user_tz":-540,"elapsed":8564,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"47d685aa-be83-4d0b-c4a6-73274ec7bd3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.0)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# 엑셀 파일 경로\n","excel_file_path = \"/content/피지오겔 크림 4.11(892개).xlsx\"\n","\n","# 데이터를 읽어올 때 인코딩 지정하지 않고 시도\n","data = pd.read_excel(excel_file_path)"],"metadata":{"id":"rst3RpvkBikv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import BertTokenizer\n","\n","# 엑셀 파일 경로 설정\n","excel_file_path = \"/content/피지오겔 크림 4.11(892개).xlsx\"\n","\n","# 읽어올 열의 이름 설정\n","column_name = \"txt_inner\"\n","\n","# 엑셀 파일에서 데이터 로드\n","data = pd.read_excel(excel_file_path)\n","\n","# 선택한 열의 데이터만 추출\n","selected_column_data = data['필드3']\n","\n","# 토크나이저를 다운로드하여 로드\n","from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel\n","\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1', last_hidden_states=True)\n","model = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n","\n","def preprocess_text(text):\n","    # 문장부호 삭제\n","    text = text.replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\";\", \"\").replace(\":\", \"\").replace(\"ㅎ\", \"\").replace(\"ㅜ\", \"\").replace(\"ㅋ\", \"\").replace(\"~\", \"\")\n","\n","    # 공백을 기준으로 단어로 분할하되, 공백이 연속으로 등장하는 경우는 하나로 합침\n","    words = []\n","    current_word = \"\"\n","    for char in text:\n","        if char == \" \":  # 공백을 만나면 현재 단어를 words에 추가하고 초기화\n","            if current_word:\n","                words.append(current_word)\n","                current_word = \"\"\n","        else:  # 공백이 아닌 경우에는 현재 단어에 추가\n","            current_word += char\n","    if current_word:  # 마지막으로 남은 단어가 있다면 추가\n","        words.append(current_word)\n","    return words\n","\n","# 전처리된 데이터를 저장할 리스트 초기화\n","preprocessed_data = []\n","\n","# 각 행의 데이터를 전처리하여 리스트에 저장\n","for index, value in selected_column_data.items():\n","    input_text = str(value)  # 각 셀의 데이터를 문자열로 변환\n","    preprocessed_text = preprocess_text(input_text)\n","    preprocessed_data.append(preprocessed_text)\n","\n","# 전처리된 데이터로 데이터프레임 생성\n","preprocessed_df = pd.DataFrame(preprocessed_data)\n","\n","# 전처리된 데이터를 새로운 엑셀 파일로 저장\n","output_excel_file = \"preprocessed_data.xlsx\"\n","preprocessed_df.to_excel(output_excel_file, index=False)\n","\n","print(\"전처리된 데이터가 {} 파일로 저장되었습니다.\".format(output_excel_file))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wi6iLuap7Y6a","executionInfo":{"status":"ok","timestamp":1714713137618,"user_tz":-540,"elapsed":6257,"user":{"displayName":"HYUN A Cho","userId":"16526649522601318226"}},"outputId":"017bda51-34b6-4918-96d9-7da898613514"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"]},{"output_type":"stream","name":"stdout","text":["전처리된 데이터가 preprocessed_data.xlsx 파일로 저장되었습니다.\n"]}]}]}